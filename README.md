# ğŸ­ Sentiment Analysis - Emotion Classification

## ğŸ“‹ Project Overview

This project performs sentiment analysis on text data to classify sentences into **6 emotion categories**:
- ğŸ˜¢ **Sadness**
- ğŸ˜Š **Joy**
- â¤ï¸ **Love**
- ğŸ˜  **Anger**
- ğŸ˜¨ **Fear**
- ğŸ˜² **Surprise**

## ğŸ¯ Project Objective

Build and evaluate a Machine Learning model to determine which emotion category a user-written sentence belongs to.

## ğŸ“Š Dataset

- **Training:** 16,000 texts
- **Validation:** 2,000 texts
- **Test:** 2,000 texts

### Emotion Distribution (Training Set):
```
Sadness:  29.16% (4,666 texts)
Joy:      33.51% (5,362 texts)
Love:      8.15% (1,304 texts)
Anger:    13.49% (2,159 texts)
Fear:     12.11% (1,937 texts)
Surprise:  3.57% (572 texts)
```

## ğŸ”¬ Methods and Techniques

### 1. Text Preprocessing
- Lowercase transformation
- Number removal
- URL and email removal
- Punctuation removal
- Extra whitespace removal

### 2. Feature Extraction
- **TF-IDF Vectorization** (5,000 features)
- N-gram range: (1, 2) - unigrams and bigrams

### 3. Model Selection
The following models were tested and compared:

| Model | Validation Accuracy |
|-------|---------------------|
| Logistic Regression | 85.30% |
| Naive Bayes | 72.05% |
| **Linear SVM** | **89.30%** âœ… |

**Linear SVM** was selected as it achieved the best performance.

## ğŸ“ˆ Model Performance

### Test Set Results:
- **Overall Accuracy:** 88.35%

### Performance by Emotion:

| Emotion | Precision | Recall | F1-Score | Support |
|---------|-----------|--------|----------|---------|
| Sadness | 0.92 | 0.92 | 0.92 | 581 |
| Joy | 0.88 | 0.93 | 0.91 | 695 |
| Love | 0.77 | 0.74 | 0.75 | 159 |
| Anger | 0.90 | 0.86 | 0.88 | 275 |
| Fear | 0.88 | 0.84 | 0.86 | 224 |
| Surprise | 0.71 | 0.61 | 0.66 | 66 |

### Key Findings:

âœ… **Strengths:**
- Sadness and Joy emotions are excellently recognized (92-93% recall)
- High overall accuracy (88.35%)
- Model performs in a balanced manner across most classes

âš ï¸ **Areas for Improvement:**
- Surprise emotion recognition is weaker (61% recall)
  - Reason: Limited samples in dataset (66 test samples)
- Love emotion is relatively harder to recognize
  - Reason: Overlaps with other emotions

## ğŸ” Error Analysis

Total errors: 233 (11.65% of test set)

**Common error patterns:**
1. Fear and Anger are confused - both have negative tone
2. Confusion between Sadness and Joy - contextual ambiguity
3. Surprise often misclassified due to limited training data

## ğŸš€ Installation and Usage

### Install Required Packages:
```bash
pip install -r requirements.txt
```

### Run the Main Script:
```bash
python sentiment_analysis.py
```

### Launch Gradio Interface (optional):
```bash
python gradio_app.py
```

## ğŸ“ File Structure

```
sentiment-analysis-project/
â”‚
â”œâ”€â”€ ğŸ“„ sentiment_analysis.py         # Main model and analysis code
â”œâ”€â”€ ğŸ“„ gradio_app.py                 # Web interface (optional)
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                     # Project documentation
â”œâ”€â”€ ğŸ“„ ANALYSIS_REPORT.md           # Detailed results analysis
â”œâ”€â”€ ğŸ“„ .gitignore                    # Git ignore file
â”‚
â”œâ”€â”€ ğŸ“Š Data Files (must be included)
â”‚   â”œâ”€â”€ training.csv                 # Training dataset (16,000 rows)
â”‚   â”œâ”€â”€ validation.csv               # Validation dataset (2,000 rows)
â”‚   â””â”€â”€ test.csv                     # Test dataset (2,000 rows)
â”‚
â””â”€â”€ ğŸ“ˆ Output Files (automatically generated)
    â”œâ”€â”€ eda_analysis.png             # EDA visualization
    â””â”€â”€ confusion_matrix.png         # Confusion matrix plot
```

## ğŸ› ï¸ Technologies

- **Python 3.8+**
- **pandas** - data manipulation
- **numpy** - numerical operations
- **scikit-learn** - machine learning models
- **matplotlib & seaborn** - visualization
- **gradio** - web interface (optional)

## ğŸ“Š Visualizations

The project generates the following plots:
1. **EDA Analysis** - Emotion distribution, text length analysis
2. **Confusion Matrix** - Visual representation of model errors

## ğŸ’¡ Future Improvements

1. **Deep Learning Models:**
   - LSTM, GRU
   - Transformer models like BERT, RoBERTa

2. **Data Augmentation:**
   - Add more samples for Surprise
   - Back-translation technique

3. **Feature Engineering:**
   - Emoji analysis
   - Part-of-speech tagging
   - Sentiment lexicon features

4. **Model Ensemble:**
   - Combine multiple models
   - Voting classifier

## ğŸ“ Test Examples

```python
test_sentences = {
    'sadness': "I feel so lonely and depressed today",
    'joy': "I am so happy and excited about this wonderful day",
    'love': "I love you so much, you make me feel complete",
    'anger': "I am so angry and frustrated with this situation",
    'fear': "I am scared and worried about what might happen",
    'surprise': "Wow, I cannot believe this is happening"
}
```

## ğŸ“ Key Learnings

1. **Text Preprocessing is crucial** - Proper cleaning improves text quality
2. **Class imbalance** problem - Some emotions are underrepresented
3. **Model Selection** - Linear SVM is optimal for this task
4. **Feature Engineering** - TF-IDF bigrams provide additional information
5. **Evaluation metrics** - Accuracy alone is not enough, precision/recall matter

## ğŸ”§ Code Usage

### Basic Usage:
```python
from sentiment_analysis import SentimentAnalyzer

# Initialize and train model
analyzer = SentimentAnalyzer()
analyzer.load_data(
    train_path='training.csv',
    val_path='validation.csv',
    test_path='test.csv'
)
analyzer.prepare_data()
analyzer.train_models()

# Make prediction
text = "I am so excited about this opportunity!"
emotion, probabilities = analyzer.predict_emotion(text)

print(f"Predicted Emotion: {emotion}")
print(f"Confidence: {probabilities[emotion]:.2%}")
```

### Expected Output:
```
Predicted Emotion: joy
Confidence: 80.90%
```

## ğŸ“ˆ Model Pipeline

```
Text Input
    â†“
Preprocessing (lowercase, remove numbers, punctuation)
    â†“
TF-IDF Vectorization (5000 features, bigrams)
    â†“
Linear SVM Classifier
    â†“
Emotion Prediction + Probabilities
```

## ğŸ¯ Performance Metrics Summary

```
Overall Test Accuracy:     88.35%
Training Time:             ~5 seconds
Inference Time:            <1ms per text
Model Size:                ~15MB
Feature Count:             5000

Best Performing Emotions:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Sadness:  92% F1-score â­â­â­â­â­
2. Joy:      91% F1-score â­â­â­â­â­
3. Anger:    88% F1-score â­â­â­â­
4. Fear:     86% F1-score â­â­â­â­
5. Love:     75% F1-score â­â­â­
6. Surprise: 66% F1-score â­â­
```

## ğŸ¤ Contributing

This project was developed for an AI internship program. Suggestions and improvements are welcome!

## ğŸ“„ License

This project is for educational purposes.

## ğŸ“§ Contact

For questions, please use the GitHub issues section.

---

**Project Status:** âœ… Complete  
**Code Quality:** Production-ready  
**Documentation:** Comprehensive  
**Test Coverage:** 88.35% accuracy on unseen data
